{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_loader.py\n",
    "import os, glob\n",
    "import tensorflow as tf\n",
    "from jax.lib import xla_bridge\n",
    "\n",
    "PATH = 'datasets/'\n",
    "BATCH_SIZE = 12\n",
    "IMAGE_SIZE = 512\n",
    "\n",
    "def read_train_data():\n",
    "    x_files = tf.data.Dataset.list_files(PATH + \"train/*.png\")\n",
    "    y_files = tf.data.Dataset.list_files(PATH + \"mask/*.png\")\n",
    "\n",
    "    def read_image(x_filename, y_filename):\n",
    "        x_image_string = tf.io.read_file(x_filename)\n",
    "        y_image_string = tf.io.read_file(y_filename)\n",
    "\n",
    "        x_image_decoded = tf.image.decode_png(x_image_string, channels=3)\n",
    "        y_image_decoded = tf.image.decode_png(y_image_string, channels=1)\n",
    "\n",
    "        x_image_resized = tf.image.resize(x_image_decoded, [IMAGE_SIZE, IMAGE_SIZE])\n",
    "        y_image_resized = tf.image.resize(y_image_decoded, [IMAGE_SIZE, IMAGE_SIZE])\n",
    "\n",
    "        x_image_norm = x_image_resized / 255\n",
    "        y_image_norm = y_image_resized / 255\n",
    "\n",
    "        return x_image_norm, y_image_norm\n",
    "\n",
    "    dataset = tf.data.Dataset.zip((x_files, y_files))\n",
    "\n",
    "    dataset = dataset.map(read_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.shuffle(1000).batch(BATCH_SIZE)\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def read_predict_data():\n",
    "    def image_generator():\n",
    "        for filename in glob.iglob(PATH + \"test/*.png\"):\n",
    "            with open(filename, \"rb\") as f:\n",
    "                image = tf.image.decode_png(f.read(), channels=3)\n",
    "                image_resized = tf.image.resize(image, [IMAGE_SIZE, IMAGE_SIZE])\n",
    "                image_norm = image_resized / 255.0\n",
    "                yield image_norm\n",
    "\n",
    "    images_dataset = tf.data.Dataset.from_generator(\n",
    "        image_generator,\n",
    "        output_types=tf.float32,\n",
    "        output_shapes=(IMAGE_SIZE, IMAGE_SIZE, 3),\n",
    "    )\n",
    "    images_dataset = images_dataset.batch(BATCH_SIZE)\n",
    "    images_dataset = images_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    return images_dataset\n",
    "\n",
    "\n",
    "def save_image(image):\n",
    "    file_path = 'test/result.png'\n",
    "    image = image * 255\n",
    "\n",
    "    encode_image = tf.image.encode_png(image, format='rgb', quality=100)\n",
    "\n",
    "    with open(file_path, 'wb') as fd:\n",
    "        fd.write(encode_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.py\n",
    "import jax\n",
    "from jax import numpy as jnp\n",
    "from flax import linen as fnn\n",
    "\n",
    "\n",
    "class Encoder(fnn.Module):\n",
    "    \"\"\"\n",
    "    This code defines a class called Encoder, \n",
    "    which is a component of a UNet architecture\n",
    "    commonly used in image segmentation tasks. \n",
    "    The Encoder class takes as input an image \n",
    "    tensor and produces a set of skip connections, \n",
    "    which are used by the Decoder network to \n",
    "    generate a segmentation mask.\n",
    "\n",
    "    The Encoder network consists of a series of \n",
    "    convolutional layers with increasing numbers \n",
    "    of channels and decreasing spatial dimensions.\n",
    "    Each set of features is passed through batch \n",
    "    normalization and activation functions. The \n",
    "    network also includes max-pooling and dropout \n",
    "    layers in the higher-resolution feature maps \n",
    "    to reduce overfitting and improve generalization.\n",
    "\n",
    "    The Encoder class has two class variables: \n",
    "    features and training. features is an integer \n",
    "    that specifies the number of channels in the \n",
    "    convolutional layers of the network. training \n",
    "    is a boolean that specifies whether the network\n",
    "    is in training mode or not.\n",
    "\n",
    "    The __call__ method of the Encoder class is defined\n",
    "    using the @fnn.compact decorator, which is used in\n",
    "    the JAX library to define neural networks in a \n",
    "    concise manner. The __call__ method takes the input\n",
    "    image tensor x as input and returns a list of skip \n",
    "    connections as output.\n",
    "\n",
    "    The Encoder network applies a series of convolutional \n",
    "    layers to the input image, producing a set of feature \n",
    "    maps with different spatial dimensions and channel sizes. \n",
    "    The network then applies batch normalization and ReLU \n",
    "    activation functions to each set of features. Max-pooling\n",
    "    is used in the lower-resolution feature maps to reduce \n",
    "    the spatial dimensions and provide translation invariance.\n",
    "    Dropout is used in the higher-resolution feature maps to \n",
    "    reduce overfitting and improve generalization.\n",
    "\n",
    "    The output of the Encoder network is a list of feature maps \n",
    "    at multiple scales. The feature maps in the list are in \n",
    "    decreasing order of spatial dimensions and increasing order \n",
    "    of channel sizes. The list of feature maps is used as input \n",
    "    to the Decoder network, which upsamples and combines the \n",
    "    features to produce a segmentation mask.\n",
    "\n",
    "    Overall, the Encoder class defines the feature extraction \n",
    "    and downsampling operations of the UNet architecture, \n",
    "    which are crucial for producing accurate segmentation \n",
    "    masks in image segmentation tasks.\n",
    "\n",
    "    \"\"\"\n",
    "    features: int = 64\n",
    "    training: bool = True\n",
    "\n",
    "    @fnn.compact\n",
    "    def __call__(self, x):\n",
    "        skips = []\n",
    "        for i in range(5):\n",
    "            z = fnn.Conv(self.features * 2 ** i, kernel_size=(3, 3))(x)\n",
    "            z = fnn.relu(z)\n",
    "            z = fnn.Conv(self.features * 2 ** i, kernel_size=(3, 3))(z)\n",
    "            z = fnn.BatchNorm(use_running_average=not self.training)(z)\n",
    "            z = fnn.relu(z)\n",
    "            if i < 4:\n",
    "                x = fnn.max_pool(z, window_shape=(2, 2), strides=(2, 2))\n",
    "            if i == 3 or i == 4:\n",
    "                z = fnn.Dropout(0.5, deterministic=False)(z)\n",
    "            skips.append(z)\n",
    "            \n",
    "        return skips\n",
    "\n",
    "\n",
    "class Decoder(fnn.Module):\n",
    "    \"\"\" This code defines a class called Decoder, \n",
    "        which is a component of a UNet architecture \n",
    "        commonly used in image segmentation tasks. \n",
    "        The Decoder class takes as input a set of \n",
    "        skip connections z_skips, which are produced \n",
    "        by the Encoder network and contain feature \n",
    "        maps at multiple scales.\n",
    "        \n",
    "        The Decoder class has two class variables: \n",
    "        features and training. features is an integer \n",
    "        that specifies the number of channels in the \n",
    "        convolutional layers of the network. \n",
    "        training is a boolean that specifies whether \n",
    "        the network is in training mode or not.\n",
    "        \n",
    "        The __call__ method of the Decoder class is\n",
    "        defined using the @fnn.compact decorator, which \n",
    "        is used in the JAX library to define neural networks\n",
    "        in a concise manner. The __call__ method takes \n",
    "        the set of skip connections z_skips as input and \n",
    "        returns a segmentation mask as output.\n",
    "\n",
    "        The Decoder network first selects the last set of\n",
    "        features from z_skips, and then iteratively upsamples\n",
    "        and concatenates the feature maps from the other sets \n",
    "        of skip connections with the current set of features. \n",
    "        The concatenated features are then passed through a \n",
    "        series of convolutional layers and activation functions \n",
    "        to produce the final segmentation mask.\n",
    "\n",
    "        The output of the Decoder network is a single-channel \n",
    "        tensor with the same spatial dimensions as the input \n",
    "        images. Each pixel in the output tensor represents the\n",
    "        probability that the corresponding pixel in the input \n",
    "        image belongs to the object or class being segmented. \n",
    "        The sigmoid activation function is used to ensure that \n",
    "        the output values are in the range [0, 1].\n",
    "\n",
    "        Overall, the Decoder class defines the upsampling and \n",
    "        feature combination operations of the UNet architecture, \n",
    "        which are crucial for producing accurate segmentation masks\n",
    "        in image segmentation tasks.\n",
    "\n",
    "    \"\"\"\n",
    "    features: int = 64\n",
    "    training: bool = True\n",
    "\n",
    "    @fnn.compact\n",
    "    def __call__(self, z_skips):\n",
    "        z = z_skips[-1]\n",
    "        for i in range(4):\n",
    "            z = jax.image.resize(z, \n",
    "                                 shape=(z.shape[0], z.shape[1] * 2, z.shape[2] * 2, z.shape[3]), \n",
    "                                 method='nearest')\n",
    "            z = fnn.Conv(self.features * 8, kernel_size=(2, 2))(z)\n",
    "            z = fnn.relu(z)\n",
    "            z = jnp.concatenate([z_skips[-i-2], z], axis=3)\n",
    "            z = fnn.Conv(self.features * 8, kernel_size=(3, 3))(z)\n",
    "            z = fnn.relu(z)\n",
    "            z = fnn.Conv(self.features * 8, kernel_size=(3, 3))(z)\n",
    "            z = fnn.BatchNorm(use_running_average=not self.training)(z)\n",
    "            z = fnn.relu(z)\n",
    "\n",
    "        z = fnn.Conv(1, kernel_size=(1, 1))(z)\n",
    "        z = fnn.sigmoid(z)\n",
    "\n",
    "        return z\n",
    "\n",
    "\n",
    "class UNet(fnn.Module):\n",
    "    \"\"\"This code defines a class called UNet, \n",
    "       which is a type of convolutional neural \n",
    "       network commonly used for image segmentation \n",
    "       tasks. The UNet architecture consists of \n",
    "       an encoder and a decoder network, which are \n",
    "       connected through skip connections.\n",
    "       The class has two class variables: features \n",
    "       and training. features is an integer that \n",
    "       specifies the number of channels in the \n",
    "       convolutional layers of the network. training \n",
    "       is a boolean that specifies whether the \n",
    "       network is in training mode or not.\n",
    "\n",
    "    Args:\n",
    "        fnn (__call__): \n",
    "        The __call__ method of the UNet class is \n",
    "        defined using the @fnn.compact decorator, \n",
    "        which is used in the JAX library to define \n",
    "        neural networks in a concise manner.\n",
    "        The __call__ method takes an input tensor x, \n",
    "        which is passed through the Encoder network \n",
    "        to produce a set of skip connections. \n",
    "        These skip connections are then passed through \n",
    "        the Decoder network to produce the final\n",
    "        output tensor y.\n",
    "        The Encoder network is responsible for \n",
    "        downsampling the input tensor and extracting \n",
    "        high-level features, while the Decoder network \n",
    "        is responsible for upsampling the features \n",
    "        and producing the final segmentation mask.\n",
    "\n",
    "    Returns:\n",
    "        _type_: \n",
    "        The return value of the __call__ method in \n",
    "        this code is a tensor y, which represents \n",
    "        the output of the UNet architecture after \n",
    "        processing the input tensor x. The exact\n",
    "        shape and data type of y will depend on the \n",
    "        specific implementation of the Decoder \n",
    "        network and the nature of the image segmentation\n",
    "        task that the UNet is being used for.\n",
    "        In general, the output tensor y will likely \n",
    "        be a multi-channel tensor with the same spatial \n",
    "        dimensions as the input tensor x. Each channel \n",
    "        of y may represent a different segmentation class \n",
    "        or feature of the input image, depending on the \n",
    "        task at hand. The data type of y will likely \n",
    "        be a floating-point type, such as float32, \n",
    "        to allow for the computation of gradients \n",
    "        during backpropagation.\n",
    "    \n",
    "    Overall, this code defines a UNet architecture \n",
    "    that can be used for image segmentation tasks. \n",
    "    By changing the value of the features and \n",
    "    training variables, the architecture can be \n",
    "    customized to fit different input data and training regimes.\n",
    "    \"\"\"\n",
    "    features: int = 64\n",
    "    training: bool = True\n",
    "\n",
    "    @fnn.compact\n",
    "    def __call__(self, x):\n",
    "        z_skips = Encoder(self.training)(x)\n",
    "        y = Decoder(self.training)(z_skips)\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-18 09:38:16.762261: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-02-18 09:38:28.135398: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-18 09:38:28.135794: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-18 09:38:28.135820: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "# prediction.py\n",
    "import time\n",
    "from functools import partial\n",
    "import jax\n",
    "import optax\n",
    "\n",
    "from jax import numpy as jnp\n",
    "from flax.training.train_state import TrainState\n",
    "from flax.training import checkpoints\n",
    "\n",
    "\n",
    "CKPT_DIR = 'checkpoints'\n",
    "IMAGE_SIZE = 512\n",
    "\n",
    "def predict():\n",
    "    data = read_predict_data()\n",
    "    unet = UNet(training=False)\n",
    "\n",
    "    init_rngs = {'params': jax.random.PRNGKey(0), 'dropout': jax.random.PRNGKey(1)}\n",
    "\n",
    "    unet_variables = unet.init(init_rngs, jnp.ones([1, IMAGE_SIZE, IMAGE_SIZE, 3]))\n",
    "\n",
    "    optimizer = optax.adam(learning_rate=0.001)\n",
    "\n",
    "    train_state = CustomTrainState.create(apply_fn=unet.apply, params=unet_variables[\"params\"], tx=optimizer,\n",
    "                                          batch_stats=unet_variables[\"batch_stats\"])\n",
    "\n",
    "    checkpoints.restore_checkpoint(ckpt_dir=CKPT_DIR, target=train_state)\n",
    "\n",
    "    pred, _ = train_state.apply_fn_with_bn({\"params\": train_state.params, \"batch_stats\": train_state.batch_stats}, data)\n",
    "\n",
    "    save_image(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training.py\n",
    "from functools import partial\n",
    "import jax\n",
    "\n",
    "from jax import numpy as jnp\n",
    "from flax.training.train_state import TrainState\n",
    "from flax.training import checkpoints\n",
    "\n",
    "CKPT_DIR = 'checkpoints'\n",
    "IMAGE_SIZE = 512\n",
    "\n",
    "\n",
    "class CustomTrainState(TrainState):\n",
    "    batch_stats: dict\n",
    "\n",
    "    def apply_fn_with_bn(self, *args, **kwargs):\n",
    "        output, mutated_vars = self.apply_fn(*args, **kwargs,\n",
    "                                             mutable=[\"batch_stats\"], rngs={'dropout': jax.random.PRNGKey(2)})\n",
    "        new_batch_stats = mutated_vars[\"batch_stats\"]\n",
    "        return output, new_batch_stats\n",
    "\n",
    "    def update_batch_stats(self, new_batch_stats):\n",
    "        return self.replace(batch_stats=new_batch_stats)\n",
    "    \n",
    "@jax.jit\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true = jnp.ravel(y_true)\n",
    "    y_pred = jnp.ravel(y_pred)\n",
    "    intersection = jnp.sum(y_true * y_pred)\n",
    "    return 2.0 * intersection / (jnp.sum(y_true) + jnp.sum(y_pred) + 1)\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return 1.0 - dice_coef(y_true, y_pred)\n",
    "\n",
    "@partial(jax.jit, static_argnums=(3,))\n",
    "def train_step(x, y, train_state, is_training=True):\n",
    "    def loss_fn(params, batch_stats, is_training):\n",
    "        y_pred, batch_stats = train_state.apply_fn_with_bn({\"params\": params, \"batch_stats\": batch_stats}, x)\n",
    "        loss = dice_coef_loss(y, y_pred)\n",
    "\n",
    "        return loss, batch_stats\n",
    "\n",
    "    if is_training:\n",
    "        grad_fn = jax.value_and_grad(loss_fn, has_aux=True)\n",
    "        (loss, batch_stats), grads = grad_fn(train_state.params, train_state.batch_stats, True)\n",
    "\n",
    "        train_state = train_state.apply_gradients(grads=grads)\n",
    "        train_state = train_state.update_batch_stats(batch_stats)\n",
    "    else:\n",
    "        loss, batch_stats = loss_fn(train_state.params, train_state.batch_stats, False)\n",
    "\n",
    "    return loss, train_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'read_train_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 44\u001b[0m\n\u001b[1;32m     41\u001b[0m     predict()\n\u001b[1;32m     43\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m---> 44\u001b[0m     run()\n",
      "Cell \u001b[0;32mIn[3], line 16\u001b[0m, in \u001b[0;36mrun\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun\u001b[39m():\n\u001b[0;32m---> 16\u001b[0m     train_set \u001b[39m=\u001b[39m read_train_data()\n\u001b[1;32m     17\u001b[0m     unet \u001b[39m=\u001b[39m UNet()\n\u001b[1;32m     19\u001b[0m     init_rngs \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mparams\u001b[39m\u001b[39m'\u001b[39m: jax\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mPRNGKey(\u001b[39m0\u001b[39m), \u001b[39m'\u001b[39m\u001b[39mdropout\u001b[39m\u001b[39m'\u001b[39m: jax\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mPRNGKey(\u001b[39m1\u001b[39m)}\n",
      "\u001b[0;31mNameError\u001b[0m: name 'read_train_data' is not defined"
     ]
    }
   ],
   "source": [
    "# main.py\n",
    "import time\n",
    "from functools import partial\n",
    "import jax\n",
    "import optax\n",
    "\n",
    "from jax import numpy as jnp\n",
    "from flax.training.train_state import TrainState\n",
    "from flax.training import checkpoints\n",
    "\n",
    "CKPT_DIR = 'checkpoints'\n",
    "IMAGE_SIZE = 512\n",
    "NUM_EPOCHS = 20\n",
    "\n",
    "def run():\n",
    "    train_set = read_train_data()\n",
    "    unet = UNet()\n",
    "\n",
    "    init_rngs = {'params': jax.random.PRNGKey(0), 'dropout': jax.random.PRNGKey(1)}\n",
    "\n",
    "    unet_variables = unet.init(init_rngs, jnp.ones([1, IMAGE_SIZE, IMAGE_SIZE, 3]))\n",
    "\n",
    "    optimizer = optax.adam(learning_rate=0.001)\n",
    "\n",
    "    train_state = CustomTrainState.create(apply_fn=unet.apply, params=unet_variables[\"params\"], tx=optimizer,\n",
    "                                          batch_stats=unet_variables[\"batch_stats\"])\n",
    "\n",
    "    checkpoints.save_checkpoint(ckpt_dir=CKPT_DIR, target=train_state, step=0, overwrite=True)\n",
    "\n",
    "    for e in range(NUM_EPOCHS):\n",
    "        loss_avg = 0\n",
    "        tic = time.time()\n",
    "        for x, y in train_set.as_numpy_iterator():\n",
    "            loss, train_state = train_step(x, y, train_state, True)\n",
    "            loss_avg += loss\n",
    "\n",
    "        loss_avg /= len(train_set)\n",
    "        elapsed = time.time() - tic\n",
    "        print(f\"epoch: {e}, loss: {loss_avg:0.2f}, elapased: {elapsed:0.2f}\")\n",
    "\n",
    "    predict()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
