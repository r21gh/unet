{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3uTm-6GBEWXm",
        "outputId": "e906d0dd-b0fa-46b0-9505-dd7e7c709ef9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2022 NVIDIA Corporation\n",
            "Built on Tue_Mar__8_18:18:20_PST_2022\n",
            "Cuda compilation tools, release 11.6, V11.6.124\n",
            "Build cuda_11.6.r11.6/compiler.31057947_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pip\n",
        "# Installs the wheel compatible with CUDA 11 and cuDNN 8.6 or newer.\n",
        "# Note: wheels only available on linux.\n",
        "!pip install --upgrade \"jax[cuda]\" -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html"
      ],
      "metadata": {
        "id": "-LaxmQUcEGW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flax optax tensorflow "
      ],
      "metadata": {
        "id": "c-_GJw6n6_xL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pip\n",
        "\n",
        "# Installs the wheel compatible with Cuda >= 11.4 and cudnn >= 8.2\n",
        "!pip install \"jax[cuda11_cudnn82]\" -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z4P7QLxUGX_y",
        "outputId": "775d201d-bcd4-473f-9b34-5e98a3c292cf"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.8/dist-packages (23.0.1)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\n",
            "Requirement already satisfied: jax[cuda11_cudnn82] in /usr/local/lib/python3.8/dist-packages (0.4.4)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.8/dist-packages (from jax[cuda11_cudnn82]) (1.7.3)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.8/dist-packages (from jax[cuda11_cudnn82]) (1.21.6)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.8/dist-packages (from jax[cuda11_cudnn82]) (3.3.0)\n",
            "Collecting jaxlib==0.4.4+cuda11.cudnn82\n",
            "  Using cached https://storage.googleapis.com/jax-releases/cuda11/jaxlib-0.4.4%2Bcuda11.cudnn82-cp38-cp38-manylinux2014_x86_64.whl (154.5 MB)\n",
            "Installing collected packages: jaxlib\n",
            "  Attempting uninstall: jaxlib\n",
            "    Found existing installation: jaxlib 0.4.4+cuda11.cudnn86\n",
            "    Uninstalling jaxlib-0.4.4+cuda11.cudnn86:\n",
            "      Successfully uninstalled jaxlib-0.4.4+cuda11.cudnn86\n",
            "Successfully installed jaxlib-0.4.4+cuda11.cudnn82\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf datasets\n",
        "!rm -rf unet\n",
        "!git clone https://github.com/r21gh/unet.git\n",
        "!mv unet/datasets .\n",
        "!rm -rf unet\n",
        "!rm -rf checkpoints\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oGl6CbVxCRuU",
        "outputId": "30f5dd9c-1a3f-46d4-9f0f-219fdcaaec47"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'unet'...\n",
            "remote: Enumerating objects: 126, done.\u001b[K\n",
            "remote: Counting objects: 100% (126/126), done.\u001b[K\n",
            "remote: Compressing objects: 100% (89/89), done.\u001b[K\n",
            "remote: Total 126 (delta 39), reused 117 (delta 34), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (126/126), 5.49 MiB | 19.60 MiB/s, done.\n",
            "Resolving deltas: 100% (39/39), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "7_o7mDnf5Xl3"
      },
      "outputs": [],
      "source": [
        "# data_loader.py\n",
        "import os, glob\n",
        "import tensorflow as tf\n",
        "from jax.lib import xla_bridge\n",
        "\n",
        "PATH = 'datasets/'\n",
        "BATCH_SIZE = 12\n",
        "IMAGE_SIZE = 512\n",
        "\n",
        "def read_train_data():\n",
        "    x_files = tf.data.Dataset.list_files(PATH + \"train/*.png\")\n",
        "    y_files = tf.data.Dataset.list_files(PATH + \"mask/*.png\")\n",
        "\n",
        "    def read_image(x_filename, y_filename):\n",
        "        x_image_string = tf.io.read_file(x_filename)\n",
        "        y_image_string = tf.io.read_file(y_filename)\n",
        "\n",
        "        x_image_decoded = tf.image.decode_png(x_image_string, channels=3)\n",
        "        y_image_decoded = tf.image.decode_png(y_image_string, channels=1)\n",
        "\n",
        "        x_image_resized = tf.image.resize(x_image_decoded, [IMAGE_SIZE, IMAGE_SIZE])\n",
        "        y_image_resized = tf.image.resize(y_image_decoded, [IMAGE_SIZE, IMAGE_SIZE])\n",
        "\n",
        "        x_image_norm = x_image_resized / 255\n",
        "        y_image_norm = y_image_resized / 255\n",
        "\n",
        "        return x_image_norm, y_image_norm\n",
        "\n",
        "    dataset = tf.data.Dataset.zip((x_files, y_files))\n",
        "\n",
        "    dataset = dataset.map(read_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "    dataset = dataset.shuffle(1000).batch(BATCH_SIZE)\n",
        "    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "    return dataset\n",
        "\n",
        "\n",
        "def read_predict_data():\n",
        "    def image_generator():\n",
        "        for filename in glob.iglob(PATH + \"test/*.png\"):\n",
        "            with open(filename, \"rb\") as f:\n",
        "                image = tf.image.decode_png(f.read(), channels=3)\n",
        "                image_resized = tf.image.resize(image, [IMAGE_SIZE, IMAGE_SIZE])\n",
        "                image_norm = image_resized / 255.0\n",
        "                yield image_norm\n",
        "\n",
        "    images_dataset = tf.data.Dataset.from_generator(\n",
        "        image_generator,\n",
        "        output_types=tf.float32,\n",
        "        output_shapes=(IMAGE_SIZE, IMAGE_SIZE, 3),\n",
        "    )\n",
        "    images_dataset = images_dataset.batch(BATCH_SIZE)\n",
        "    images_dataset = images_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "    return images_dataset\n",
        "\n",
        "\n",
        "def save_image(image):\n",
        "    file_path = 'test/result.png'\n",
        "    image = image * 255\n",
        "\n",
        "    encode_image = tf.image.encode_png(image, format='rgb', quality=100)\n",
        "\n",
        "    with open(file_path, 'wb') as fd:\n",
        "        fd.write(encode_image)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model.py\n",
        "import jax\n",
        "from jax import numpy as jnp\n",
        "from flax import linen as fnn\n",
        "\n",
        "\n",
        "class Encoder(fnn.Module):\n",
        "    \"\"\"\n",
        "    This code defines a class called Encoder, \n",
        "    which is a component of a UNet architecture\n",
        "    commonly used in image segmentation tasks. \n",
        "    The Encoder class takes as input an image \n",
        "    tensor and produces a set of skip connections, \n",
        "    which are used by the Decoder network to \n",
        "    generate a segmentation mask.\n",
        "\n",
        "    The Encoder network consists of a series of \n",
        "    convolutional layers with increasing numbers \n",
        "    of channels and decreasing spatial dimensions.\n",
        "    Each set of features is passed through batch \n",
        "    normalization and activation functions. The \n",
        "    network also includes max-pooling and dropout \n",
        "    layers in the higher-resolution feature maps \n",
        "    to reduce overfitting and improve generalization.\n",
        "\n",
        "    The Encoder class has two class variables: \n",
        "    features and training. features is an integer \n",
        "    that specifies the number of channels in the \n",
        "    convolutional layers of the network. training \n",
        "    is a boolean that specifies whether the network\n",
        "    is in training mode or not.\n",
        "\n",
        "    The __call__ method of the Encoder class is defined\n",
        "    using the @fnn.compact decorator, which is used in\n",
        "    the JAX library to define neural networks in a \n",
        "    concise manner. The __call__ method takes the input\n",
        "    image tensor x as input and returns a list of skip \n",
        "    connections as output.\n",
        "\n",
        "    The Encoder network applies a series of convolutional \n",
        "    layers to the input image, producing a set of feature \n",
        "    maps with different spatial dimensions and channel sizes. \n",
        "    The network then applies batch normalization and ReLU \n",
        "    activation functions to each set of features. Max-pooling\n",
        "    is used in the lower-resolution feature maps to reduce \n",
        "    the spatial dimensions and provide translation invariance.\n",
        "    Dropout is used in the higher-resolution feature maps to \n",
        "    reduce overfitting and improve generalization.\n",
        "\n",
        "    The output of the Encoder network is a list of feature maps \n",
        "    at multiple scales. The feature maps in the list are in \n",
        "    decreasing order of spatial dimensions and increasing order \n",
        "    of channel sizes. The list of feature maps is used as input \n",
        "    to the Decoder network, which upsamples and combines the \n",
        "    features to produce a segmentation mask.\n",
        "\n",
        "    Overall, the Encoder class defines the feature extraction \n",
        "    and downsampling operations of the UNet architecture, \n",
        "    which are crucial for producing accurate segmentation \n",
        "    masks in image segmentation tasks.\n",
        "\n",
        "    \"\"\"\n",
        "    features: int = 64\n",
        "    training: bool = True\n",
        "\n",
        "    @fnn.compact\n",
        "    def __call__(self, x):\n",
        "        skips = []\n",
        "        for i in range(5):\n",
        "            z = fnn.Conv(self.features * 2 ** i, kernel_size=(3, 3))(x)\n",
        "            z = fnn.relu(z)\n",
        "            z = fnn.Conv(self.features * 2 ** i, kernel_size=(3, 3))(z)\n",
        "            z = fnn.BatchNorm(use_running_average=not self.training)(z)\n",
        "            z = fnn.relu(z)\n",
        "            if i < 4:\n",
        "                x = fnn.max_pool(z, window_shape=(2, 2), strides=(2, 2))\n",
        "            if i == 3 or i == 4:\n",
        "                z = fnn.Dropout(0.5, deterministic=False)(z)\n",
        "            skips.append(z)\n",
        "            \n",
        "        return skips\n",
        "\n",
        "\n",
        "class Decoder(fnn.Module):\n",
        "    \"\"\" This code defines a class called Decoder, \n",
        "        which is a component of a UNet architecture \n",
        "        commonly used in image segmentation tasks. \n",
        "        The Decoder class takes as input a set of \n",
        "        skip connections z_skips, which are produced \n",
        "        by the Encoder network and contain feature \n",
        "        maps at multiple scales.\n",
        "        \n",
        "        The Decoder class has two class variables: \n",
        "        features and training. features is an integer \n",
        "        that specifies the number of channels in the \n",
        "        convolutional layers of the network. \n",
        "        training is a boolean that specifies whether \n",
        "        the network is in training mode or not.\n",
        "        \n",
        "        The __call__ method of the Decoder class is\n",
        "        defined using the @fnn.compact decorator, which \n",
        "        is used in the JAX library to define neural networks\n",
        "        in a concise manner. The __call__ method takes \n",
        "        the set of skip connections z_skips as input and \n",
        "        returns a segmentation mask as output.\n",
        "\n",
        "        The Decoder network first selects the last set of\n",
        "        features from z_skips, and then iteratively upsamples\n",
        "        and concatenates the feature maps from the other sets \n",
        "        of skip connections with the current set of features. \n",
        "        The concatenated features are then passed through a \n",
        "        series of convolutional layers and activation functions \n",
        "        to produce the final segmentation mask.\n",
        "\n",
        "        The output of the Decoder network is a single-channel \n",
        "        tensor with the same spatial dimensions as the input \n",
        "        images. Each pixel in the output tensor represents the\n",
        "        probability that the corresponding pixel in the input \n",
        "        image belongs to the object or class being segmented. \n",
        "        The sigmoid activation function is used to ensure that \n",
        "        the output values are in the range [0, 1].\n",
        "\n",
        "        Overall, the Decoder class defines the upsampling and \n",
        "        feature combination operations of the UNet architecture, \n",
        "        which are crucial for producing accurate segmentation masks\n",
        "        in image segmentation tasks.\n",
        "\n",
        "    \"\"\"\n",
        "    features: int = 64\n",
        "    training: bool = True\n",
        "\n",
        "    @fnn.compact\n",
        "    def __call__(self, z_skips):\n",
        "        z = z_skips[-1]\n",
        "        for i in range(4):\n",
        "            z = jax.image.resize(z, \n",
        "                                 shape=(z.shape[0], z.shape[1] * 2, z.shape[2] * 2, z.shape[3]), \n",
        "                                 method='nearest')\n",
        "            z = fnn.Conv(self.features * 8, kernel_size=(2, 2))(z)\n",
        "            z = fnn.relu(z)\n",
        "            z = jnp.concatenate([z_skips[-i-2], z], axis=3)\n",
        "            z = fnn.Conv(self.features * 8, kernel_size=(3, 3))(z)\n",
        "            z = fnn.relu(z)\n",
        "            z = fnn.Conv(self.features * 8, kernel_size=(3, 3))(z)\n",
        "            z = fnn.BatchNorm(use_running_average=not self.training)(z)\n",
        "            z = fnn.relu(z)\n",
        "\n",
        "        z = fnn.Conv(1, kernel_size=(1, 1))(z)\n",
        "        z = fnn.sigmoid(z)\n",
        "\n",
        "        return z\n",
        "\n",
        "\n",
        "class UNet(fnn.Module):\n",
        "    \"\"\"This code defines a class called UNet, \n",
        "       which is a type of convolutional neural \n",
        "       network commonly used for image segmentation \n",
        "       tasks. The UNet architecture consists of \n",
        "       an encoder and a decoder network, which are \n",
        "       connected through skip connections.\n",
        "       The class has two class variables: features \n",
        "       and training. features is an integer that \n",
        "       specifies the number of channels in the \n",
        "       convolutional layers of the network. training \n",
        "       is a boolean that specifies whether the \n",
        "       network is in training mode or not.\n",
        "\n",
        "    Args:\n",
        "        fnn (__call__): \n",
        "        The __call__ method of the UNet class is \n",
        "        defined using the @fnn.compact decorator, \n",
        "        which is used in the JAX library to define \n",
        "        neural networks in a concise manner.\n",
        "        The __call__ method takes an input tensor x, \n",
        "        which is passed through the Encoder network \n",
        "        to produce a set of skip connections. \n",
        "        These skip connections are then passed through \n",
        "        the Decoder network to produce the final\n",
        "        output tensor y.\n",
        "        The Encoder network is responsible for \n",
        "        downsampling the input tensor and extracting \n",
        "        high-level features, while the Decoder network \n",
        "        is responsible for upsampling the features \n",
        "        and producing the final segmentation mask.\n",
        "\n",
        "    Returns:\n",
        "        _type_: \n",
        "        The return value of the __call__ method in \n",
        "        this code is a tensor y, which represents \n",
        "        the output of the UNet architecture after \n",
        "        processing the input tensor x. The exact\n",
        "        shape and data type of y will depend on the \n",
        "        specific implementation of the Decoder \n",
        "        network and the nature of the image segmentation\n",
        "        task that the UNet is being used for.\n",
        "        In general, the output tensor y will likely \n",
        "        be a multi-channel tensor with the same spatial \n",
        "        dimensions as the input tensor x. Each channel \n",
        "        of y may represent a different segmentation class \n",
        "        or feature of the input image, depending on the \n",
        "        task at hand. The data type of y will likely \n",
        "        be a floating-point type, such as float32, \n",
        "        to allow for the computation of gradients \n",
        "        during backpropagation.\n",
        "    \n",
        "    Overall, this code defines a UNet architecture \n",
        "    that can be used for image segmentation tasks. \n",
        "    By changing the value of the features and \n",
        "    training variables, the architecture can be \n",
        "    customized to fit different input data and training regimes.\n",
        "    \"\"\"\n",
        "    features: int = 64\n",
        "    training: bool = True\n",
        "\n",
        "    @fnn.compact\n",
        "    def __call__(self, x):\n",
        "        z_skips = Encoder(self.training)(x)\n",
        "        y = Decoder(self.training)(z_skips)\n",
        "\n",
        "        return y"
      ],
      "metadata": {
        "id": "qDW0WUhg54IY"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prediction.py\n",
        "import time\n",
        "from functools import partial\n",
        "import jax\n",
        "import optax\n",
        "\n",
        "from jax import numpy as jnp\n",
        "from flax.training.train_state import TrainState\n",
        "from flax.training import checkpoints\n",
        "\n",
        "\n",
        "CKPT_DIR = 'checkpoints'\n",
        "IMAGE_SIZE = 512\n",
        "\n",
        "def predict():\n",
        "    data = read_predict_data()\n",
        "    unet = UNet(training=False)\n",
        "\n",
        "    init_rngs = {'params': jax.random.PRNGKey(0), 'dropout': jax.random.PRNGKey(1)}\n",
        "\n",
        "    unet_variables = unet.init(init_rngs, jnp.ones([1, IMAGE_SIZE, IMAGE_SIZE, 3]))\n",
        "\n",
        "    optimizer = optax.adam(learning_rate=0.001)\n",
        "\n",
        "    train_state = CustomTrainState.create(apply_fn=unet.apply, params=unet_variables[\"params\"], tx=optimizer,\n",
        "                                          batch_stats=unet_variables[\"batch_stats\"])\n",
        "\n",
        "    checkpoints.restore_checkpoint(ckpt_dir=CKPT_DIR, target=train_state)\n",
        "\n",
        "    pred, _ = train_state.apply_fn_with_bn({\"params\": train_state.params, \"batch_stats\": train_state.batch_stats}, data)\n",
        "\n",
        "    save_image(pred)"
      ],
      "metadata": {
        "id": "4noZQRyR5473"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training.py\n",
        "from functools import partial\n",
        "import jax\n",
        "\n",
        "from jax import numpy as jnp\n",
        "from flax.training.train_state import TrainState\n",
        "from flax.training import checkpoints\n",
        "\n",
        "CKPT_DIR = 'checkpoints'\n",
        "IMAGE_SIZE = 512\n",
        "\n",
        "\n",
        "class CustomTrainState(TrainState):\n",
        "    batch_stats: dict\n",
        "\n",
        "    def apply_fn_with_bn(self, *args, **kwargs):\n",
        "        output, mutated_vars = self.apply_fn(*args, **kwargs,\n",
        "                                             mutable=[\"batch_stats\"], rngs={'dropout': jax.random.PRNGKey(2)})\n",
        "        new_batch_stats = mutated_vars[\"batch_stats\"]\n",
        "        return output, new_batch_stats\n",
        "\n",
        "    def update_batch_stats(self, new_batch_stats):\n",
        "        return self.replace(batch_stats=new_batch_stats)\n",
        "    \n",
        "@jax.jit\n",
        "def dice_coef(y_true, y_pred):\n",
        "    y_true = jnp.ravel(y_true)\n",
        "    y_pred = jnp.ravel(y_pred)\n",
        "    intersection = jnp.sum(y_true * y_pred)\n",
        "    return 2.0 * intersection / (jnp.sum(y_true) + jnp.sum(y_pred) + 1)\n",
        "\n",
        "\n",
        "@jax.jit\n",
        "def dice_coef_loss(y_true, y_pred):\n",
        "    return 1.0 - dice_coef(y_true, y_pred)\n",
        "\n",
        "@partial(jax.jit, static_argnums=(3,))\n",
        "def train_step(x, y, train_state, is_training=True):\n",
        "    def loss_fn(params, batch_stats, is_training):\n",
        "        y_pred, batch_stats = train_state.apply_fn_with_bn({\"params\": params, \"batch_stats\": batch_stats}, x)\n",
        "        loss = dice_coef_loss(y, y_pred)\n",
        "\n",
        "        return loss, batch_stats\n",
        "\n",
        "    if is_training:\n",
        "        grad_fn = jax.value_and_grad(loss_fn, has_aux=True)\n",
        "        (loss, batch_stats), grads = grad_fn(train_state.params, train_state.batch_stats, True)\n",
        "\n",
        "        train_state = train_state.apply_gradients(grads=grads)\n",
        "        train_state = train_state.update_batch_stats(batch_stats)\n",
        "    else:\n",
        "        loss, batch_stats = loss_fn(train_state.params, train_state.batch_stats, False)\n",
        "\n",
        "    return loss, train_state"
      ],
      "metadata": {
        "id": "ChZQnde_59Eo"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# main.py\n",
        "import time\n",
        "from functools import partial\n",
        "import jax\n",
        "import optax\n",
        "\n",
        "from jax import numpy as jnp\n",
        "from flax.training.train_state import TrainState\n",
        "from flax.training import checkpoints\n",
        "\n",
        "CKPT_DIR = 'checkpoints'\n",
        "IMAGE_SIZE = 512\n",
        "NUM_EPOCHS = 20\n",
        "\n",
        "def run():\n",
        "    train_set = read_train_data()\n",
        "    unet = UNet()\n",
        "\n",
        "    init_rngs = {'params': jax.random.PRNGKey(0), 'dropout': jax.random.PRNGKey(1)}\n",
        "\n",
        "    unet_variables = unet.init(init_rngs, jnp.ones([1, IMAGE_SIZE, IMAGE_SIZE, 3]))\n",
        "\n",
        "    optimizer = optax.adam(learning_rate=0.001)\n",
        "\n",
        "    train_state = CustomTrainState.create(apply_fn=unet.apply, params=unet_variables[\"params\"], tx=optimizer,\n",
        "                                          batch_stats=unet_variables[\"batch_stats\"])\n",
        "\n",
        "    checkpoints.save_checkpoint(ckpt_dir=CKPT_DIR, target=train_state, step=0, overwrite=True)\n",
        "\n",
        "    for e in range(NUM_EPOCHS):\n",
        "        loss_avg = 0\n",
        "        tic = time.time()\n",
        "        for x, y in train_set.as_numpy_iterator():\n",
        "            loss, train_state = train_step(x, y, train_state, True)\n",
        "            loss_avg += loss\n",
        "\n",
        "        loss_avg /= len(train_set)\n",
        "        elapsed = time.time() - tic\n",
        "        print(f\"epoch: {e}, loss: {loss_avg:0.2f}, elapased: {elapsed:0.2f}\")\n",
        "\n",
        "    predict()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    run()"
      ],
      "metadata": {
        "id": "kxdaDp886Alj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}